{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium 실행\n",
    "# 크롬브라우저 실행하기\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "driver = webdriver.Chrome('C:/Users/kikik/Downloads/webcrawling/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://comic.naver.com/webtoon/genre.nhn?view=list&order=User&genre=episode\"\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 웹툰 제목\n",
    "webtoon = soup.select('tbody > tr')\n",
    "len(webtoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독립일기\n"
     ]
    }
   ],
   "source": [
    "# 영화 제목\n",
    "webtoon = soup.select('tbody > tr')\n",
    "title = soup.select('td.subject > a')[0].text\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'select'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dc7d61fb6b27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwebtoons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.list_area.table_list_area > table > tbody > tr.first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebtoons\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'td.subject > a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2172\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2173\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2174\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2175\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'select'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "webtoons = soup.select('div.list_area.table_list_area > table > tbody > tr.first')\n",
    "title = webtoons.select('td.subject > a')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/webtoon/list.nhn?titleId=748105\" onclick=\"nclk_v2(event,'lst.title','748105','1')\"><strong title=\"독립일기\">독립일기</strong></a>]\n"
     ]
    }
   ],
   "source": [
    "webtoons = soup.select('div.list_area.table_list_area > table > tbody > tr.first')\n",
    "title = webtoons[0].select('td.subject > a')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.98\n"
     ]
    }
   ],
   "source": [
    "rating = soup.select('div.list_area.table_list_area table > tbody > tr.first > td:nth-child(2) > div > strong')[0].text\n",
    "print(rating)\n",
    "#content > div.list_area.table_list_area > table > tbody > tr.first > td:nth-child(2) > div > span > em\n",
    "#content > div.list_area.table_list_area > table > tbody > tr.first > td:nth-child(2) > div > strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자까\n"
     ]
    }
   ],
   "source": [
    "artist = soup.select('div.list_area.table_list_area > table > tbody > tr.first > td:nth-child(3) > a')[0].text\n",
    "print(artist)\n",
    "\n",
    "#content > div.list_area.table_list_area > table > tbody > tr.first > td:nth-child(3) > a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독립일기|9.98|자까\n",
      "모죠의 일지|9.97|모죠\n",
      "한림체육관|9.71|혜성 / 이석재\n",
      "인생존망|9.85|박태준 / 전선욱\n",
      "노곤하개|9.98|홍끼\n",
      "호랑이 들어와요|9.95|배세혁 / 유은\n",
      "삼국지톡|9.94|무적핑크 / 이리\n",
      "세상은 돈과 권력|9.89|한동우 / 이도희\n",
      "곱게 키웠더니, 짐승|9.92|이른꽃,티바 / 여슬기\n",
      "닥터앤닥터 육아일기|9.98|닥터베르\n",
      "칼가는 소녀|9.97|오리\n",
      "겟백|9.98|세윤\n",
      "나쁜사람|9.82|둠스\n",
      "오로지 너를 이기고 싶어|9.96|아마도지 / 사삭\n",
      "병의 기록|9.76|베어리\n",
      "오늘의 순정망화|9.98|손하기\n",
      "윌유메리미|9.93|마인드C\n",
      "지옥급식|9.40|둘기마요\n",
      "언덕 위의 제임스|9.92|쿠당탕\n",
      "범이올시다!|9.98|해\n",
      "피로만땅|9.88|샤니\n",
      "바른탕진 프로젝트|9.75|점삼\n",
      "서브 콤플렉스|9.94|소이\n",
      "헬프미|9.17|철준\n",
      "홍시는 날 좋아해!|9.97|강하다 / 웃는해\n",
      "유미의 세포들|9.93|이동건\n",
      "웰캄투실버라이프|9.98|솔녀\n",
      "강림전기 개정기|9.26|철무장미 / 장군\n",
      "약한영웅|9.90|서패스 / 김진석\n",
      "진짜 정말 맹세코 좋아해|9.89|개차반 / 잠괴물\n",
      "자판귀|9.95|윤정민\n",
      "대학일기|9.97|자까\n",
      "인터셉트|9.92|임주이\n",
      "회춘|9.73|기안84\n",
      "불발소년|9.86|곤세\n",
      "수상한 비밀상담부|9.93|149\n",
      "화장 지워주는 남자|9.94|이연\n",
      "마음의소리|9.86|조석\n",
      "다함께 이겨내요|9.88|웹툰작가\n",
      "놓지마 정신줄|9.92|신태훈 / 나승훈\n",
      "조선왕조실톡|9.89|무적핑크\n",
      "힘내요 일본!-[릴레이웹툰]|6.99|웹툰작가\n",
      "수능일기|9.98|자까\n",
      "만물의 영장|9.98|보민\n",
      "놓지마 정신줄 시즌2|9.95|신태훈 / 나승훈\n",
      "MLB카툰|8.04|최훈\n",
      "2020 최애캐의 MBTI|9.65|웹툰작가\n",
      "역전! 야매요리|9.83|정다정\n",
      "와탕카|9.63|우주인\n",
      "지옥|9.77|연상호 / 최규석\n",
      "밥 먹고 갈래요?|9.97|오묘\n",
      "203호 저승사자|9.91|샤니\n",
      "선천적 얼간이들|9.98|가스파드\n",
      "돼지만화|4.56|돼지작가\n",
      "낢이 사는 이야기|9.83|서나래\n",
      "골방환상곡|9.92|워니 / 심윤수\n",
      "터치! 메리크리스마스|9.78|웹툰작가\n",
      "공감.jpg|4.44|임총\n",
      "슈퍼 시크릿|9.98|이온\n",
      "생활의참견|9.95|김양수\n",
      "가우스전자 시즌3~4|9.97|곽백수\n",
      "2019 루키 단편선-지옥...|9.88|웹툰작가\n",
      "자취로운 생활|9.96|츄카피\n",
      "오빠 왔다|9.70|모나\n",
      "웅이는 배고파|9.73|박웅\n",
      "우리집에 곰이 이사왔다|9.97|켄타\n",
      "와라! 편의점|9.85|지강민\n",
      "패밀리 사이즈|9.96|남지은 / 김인호\n",
      "2D남친 별책부록|9.82|웹툰작가\n",
      "나는 귀머거리다|9.98|라일라\n",
      "스퍼맨: 현자단의 역습|9.95|하일권\n",
      "살인자o난감|9.97|꼬마비 / 노마비\n",
      "혈액형에 관한 간단한 고찰|9.89|박동선\n",
      "Penguin loves ...|9.96|펭귄\n",
      "트라우마|9.92|곽백수\n",
      "2019 병영일기|9.83|웹툰작가\n",
      "모두에게 완자가|9.71|완자\n",
      "플라워(FLOWAR)|9.93|홍작가\n",
      "스퍼맨 시즌2|9.97|하일권\n",
      "오늘도 형제는 평화롭다|9.97|GIMS\n",
      "여탕보고서|9.95|마일로\n",
      "공포단편선X|9.72|김대일\n",
      "달콤한 인생|9.95|이동건\n",
      "실질객관동화|9.90|무적핑크\n",
      "내 ID는 강남미인! - ...|9.96|기맹기\n",
      "빙탕후루|9.96|장희 / 주호민\n",
      "스마트폰 게임 개발 이야기|9.74|유영욱\n",
      "일상날개짓|9.94|나유진\n",
      "낢 부럽지 않은 신혼여행기|9.97|서나래\n",
      "사소한 냐냐|9.86|LICO\n",
      "썸남|9.97|배철완\n",
      "아랫집 시누이|9.95|김진\n",
      "언럭키 맨션|9.98|약국\n",
      "갸오오와 사랑꾼들|9.94|갸오오\n",
      "소년들은 무엇을 하고 있을까|9.41|컷부\n",
      "우리 사장님은 개|9.94|레나\n",
      "일진에게 회초리|9.95|유승연\n",
      "오늘 밤은 어둠이 무서워요|9.96|김진\n",
      "와탕카2|8.99|우주인\n",
      "식스센스|9.23|릴레이연재\n",
      "조석축구만화|9.81|조석\n",
      "판다독|9.84|판다독\n",
      "환생동물학교|9.99|엘렌 심\n",
      "네이버 앱피소드|9.63|웹툰작가\n",
      "푸들과 Dog거중|9.98|최삡뺩\n",
      "모던패밀리 2|9.68|외눈박이 / 시현\n",
      "텍사스홀덤|9.87|onesound\n",
      "빨간책|9.78|랑또\n",
      "2016 학교 다녀오겠습니다|9.41|웹툰작가\n",
      "만렙소녀 오오라|9.47|김규삼\n",
      "열대어|9.94|실버벨\n",
      "홍차리브레|9.98|꼬모소이\n",
      "3인칭|9.94|꼬마비 / 애마비\n",
      "백귀야행지|9.88|아만(阿慢)\n",
      "스쿨홀릭|9.89|신의철\n",
      "구석구석캠페인|9.21|네이버 웹툰 작가\n",
      "실질객관영화|9.73|무적핑크\n",
      "한국만화 또 다른 시선|9.75|웹툰작가\n",
      "한국만화거장전 : 만화보물섬|9.88|한국만화가협회\n",
      "보글보글|9.91|요나\n",
      "내 여자친구는 상남자|9.97|맛스타\n",
      "선녀님은 휴가중|9.40|으늬\n",
      "데우스 엑스 마키나|9.93|꼬마비\n",
      "부토|9.92|정현주\n",
      "내 어린고양이와 늙은개|9.91|초\n",
      "취업의소리|9.16|조석,워니\n",
      "메이크 업 드림 - Mak...|7.12|김계란 X 네이버웹툰\n",
      "일편단심화|9.80|심윤수\n",
      "오빠야 누나야|9.62|긴유\n",
      "아이돌 연구소|9.45|해마 / 연제원\n",
      "엔드리스|9.96|윤준식 / 박하연\n",
      "만화사랑 캠페인|6.28|웹툰작가\n",
      "아프니까 병원이다|9.89|고리타\n",
      "아이키우는만화|9.46|쇼쇼\n",
      "갓!김치|7.38|김민우\n",
      "성공한 덕후|9.89|옛사람\n",
      "부부생활|9.94|써니사이드업\n",
      "구름의 이동속도|9.98|김이랑\n",
      "창공의 타이양사무소|9.96|박유나\n",
      "잡다한컷|9.91|그림왕양치기\n",
      "암흑도시|9.93|정뱅\n",
      "오늘도 핸드메이드!|9.97|소영\n",
      "열정호구|9.93|솔뱅이\n",
      "개편 축하 릴레이 카툰|9.55|네이버웹툰작가\n",
      "27-10|9.93|AJS\n",
      "만 화 고|7.22|김8\n",
      "도자기|9.78|호연\n",
      "Yes my boss(예스...|9.97|김밀콩\n",
      "세상과 하늘 사이|9.09|우기리\n",
      "불괴|9.40|폭주필 / 폭주작\n",
      "2011 루키 단편선-지옥...|9.81|웹툰작가\n",
      "내일은 웹툰|9.88|신의철\n",
      "움비처럼|9.89|권혁주\n",
      "스마일브러시|9.94|와루\n",
      "2인용 인간|9.86|WONDER\n",
      "와장창창! 자취맨|9.95|폭타\n",
      "1인용 기분|9.97|윤파랑\n",
      "까뱅|8.82|X-TEAM\n",
      "엄마와 딸 x2|9.97|필냉이\n",
      "스마일 브러시, 오래된 사...|9.94|와루\n",
      "겨울동화|9.89|심윤수\n",
      "밥풀때기|9.80|Dylan / DanBra...\n",
      "가족의 초상|9.79|김승택\n",
      "태릉좀비촌|9.37|하얀독수리\n",
      "어른의 계절|9.83|선홍달\n",
      "토니와 함께|9.92|정성완\n",
      "우리 안의 주|9.13|폭스바니\n",
      "견원지간 로맨스|9.61|최현옥 / 고방\n",
      "피터팬날다|8.82|서랍천사\n",
      "영월동 534번지|9.79|임성훈 / 정보근\n",
      "판타스틱 어른백서|9.03|이동욱\n",
      "한스와 에밀리|9.92|김지효\n",
      "동경소녀|9.66|로보타 / 김가륜\n",
      "징글정글|9.81|김용진\n"
     ]
    }
   ],
   "source": [
    "webtoons = soup.select('tbody > tr')\n",
    "for webtoon in webtoons:\n",
    "    title = webtoon.select('td.subject > a')[0].text\n",
    "    rating = webtoon.select('div > strong')[0].text\n",
    "    artist = webtoon.select('td:nth-child(3) > a')[0].text\n",
    "    print(title,rating,artist,sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "webtoon_data = []\n",
    "number = 1\n",
    "webtoons = soup.select('tbody > tr')\n",
    "for webtoon in webtoons:\n",
    "    title = webtoon.select('td.subject > a')[0].text\n",
    "    rating = webtoon.select('div > strong')[0].text\n",
    "    writer = webtoon.select('td:nth-child(3) > a')[0].text\n",
    "    webtoon_data.append(['webtoon', title, rating, writer]) \n",
    "    number = number + 1\n",
    "columns = ['웹툰', '제목', '평점', '작가']\n",
    "pd_data = pd.DataFrame(webtoon_data, columns = columns) \n",
    "pd_data.to_excel('C:/Users/kikik/Downloads/webcrawling/webtoon.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib 실행\n",
    "# 크롬브라우저 실행하기\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(\"https://comic.naver.com/webtoon/weekday.nhn\")\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "html.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 웹툰 제목\n",
    "webtoon = soup.select('div > a')\n",
    "len(webtoon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "webtoon =soup.select('div.thumb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# urllib 실행\n",
    "# 크롬브라우저 실행하기\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import re\n",
    "\n",
    "html = requests.get(\"https://comic.naver.com/webtoon/weekday.nhn\")\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "html.close()\n",
    "\n",
    "webtoon =soup.select('div.thumb')\n",
    "\n",
    "for li in webtoon:\n",
    "    images = li.select('a > img')[0]\n",
    "    image = images['src']\n",
    "    title2 = images['title']\n",
    "    title2 = re.sub('[^0-9a-zA-Zㄱ-힗]','',title2)\n",
    "    urlretrieve(image,'C:/Users/kikik/Downloads/webtoon/'+title2+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from urllib.request import urlretrieve\n",
    "from pprint import pprint\n",
    "\n",
    "html = urllib.request.urlopen(\"https://comic.naver.com/webtoon/weekday.nhn\")\n",
    "soup = BeautifulSoup(html.read(),\"html.parser\") #웹 페이지 파싱\n",
    "html.close()\n",
    "\n",
    "\n",
    "data1_list=soup.findAll('div.col_inner')\n",
    "\n",
    "#전체 웹툰 리스트\n",
    "li_list = []\n",
    "for data1 in data1_list:\n",
    "    li_list.extend(data1.findAll('li'))\n",
    "\n",
    "for li in li_list:\n",
    "    img = li.find('img')\n",
    "    title = img['title']\n",
    "    img_src = img['src']\n",
    "    urlretrieve(img_src,'C:/Users/kikik/Downloads/webtoon/'+title2+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data1_list=soup.findAll('div.col_inner')\n",
    "print(data1_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "html = requests.get(\"https://comic.naver.com/webtoon/weekday.nhn\")\n",
    "soup = BeautifulSoup(html.text,\"html.parser\") #웹 페이지 파싱\n",
    "html.close()\n",
    "\n",
    "webtoon=soup.select('div.thumb')\n",
    "\n",
    "#각각 썸네일과 제목 추출하기\n",
    "for li in webtoon :\n",
    "    img = li.select('div > a')\n",
    "    \n",
    "    title = img['title']\n",
    "    img_src = img['src']\n",
    "    #print(title, img_src)\n",
    "    urlretrieve(img_src, 'C:/Users/kikik/Downloads/webtoon'+title+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib 실행\n",
    "# 크롬브라우저 실행하기\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import re\n",
    "\n",
    "html = requests.get(\"https://comic.naver.com/webtoon/weekday.nhn\")\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "html.close()\n",
    "\n",
    "webtoon =soup.select('div.thumb')\n",
    "\n",
    "for li in webtoon:\n",
    "    images = li.select('a > img')[0]\n",
    "    image = images['src']\n",
    "    title2 = images['title']\n",
    "    title2 = re.sub('[^0-9a-zA-Zㄱ-힗]','',title2)\n",
    "    urlretrieve(image,'C:/Users/kikik/Downloads/webtoon/'+title2+'.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
